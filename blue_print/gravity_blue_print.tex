\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage{amsmath}
\usepackage{hyperref}
\hypersetup{colorlinks=true}
\usepackage{colortbl}
\pagecolor[rgb]{1,.98,.9}

\title{Gravity: Distributed ledger data management protocol.}
\author{}
\date{March, 29, 2018.}

\begin{document}

\maketitle

\begin{abstract}
The concept of distributed ledger based cryptography protected transactions has
demonstrated its efficiency in a series of projects. The fourth industrial revolution applies a new level of standards to decentralized protocols. The Gravity project looks at the distributed ledger functions through the prism of needs of daily life produced data array management in a digitalized society. The protocol architecture aims to correspond with such necessity using the Delegated Proof of Importance (DPoI) consensus algorithm. DPoI is a high-performance energy effective network growth inducing algorithm that rewards the network participants (Nodes) for the system’s economy enhancing activity (operations). Delegated Proof of Importance is an upgrade of the existing blockchain solutions that integrates the concepts of the Delegated Proof of Stake (DPoS) and the Network Theory (the Graph Theory)
The Gravity Platform implements protocol level voting which makes Gravity a Decentralized
Autonomous Organization (DAO) that allows the network participants form and carry out the
system development strategy. The system protocol is designed in compliance with business
and end user requirements such as privacy, auditability and smooth volatility achieved due
to the dynamic emission proportionate to both the network activity growth and its volume. \cite{Metcalfe}.

\end{abstract}

\section {Introduction}
The recent years have marked an unprecedented growth of interest in the blockchain
technologies which has so far been primarily applied in distributed payment networks. Such
networks are decentralized and enable fast low cost transactions avoiding the middlemen.
Although the economic benefits and disadvantages of blockchain-based networks are
subject to a rigorous examination, within this article we are planning to consider the technical
aspects of the blockchain consensus algorithms. The blockchain consensus algorithm is a
mechanism that allows the network nodes reach the consensus about the contents of the
transaction record (ledger) in the absence of a centralized ledger keeper.
The consensus algorithm is the very basis of any blockchain network that mainly determines
its technical characteristics.

\subsection{Previous Work}
First time the problem of a distributed consensus for networks with potentially fraudulent
nodes (the Byzantine Generals’ Problem) was stated long before the creation of blockchain
in 1982. \cite{Lamport} Since then there has been developed an array of different solutions \cite{Castro},
however, the first solution applied to blockchain was the Proof-of-Work (PoW) algorithm,
described in Satoshi Nakamoto’s article. \cite{satoshi} Despite its advantages, PoW is characterised by
a number of shortcomings: scalability and performance problems \cite{Croman}, security \cite{Eyal},
progressive centralization of the networks around the largest mining pools \cite{Buterin}, and most
importantly the necessity to use vast volumes of real resources, such as electricity and
computing powers to generate every block (i.e. tasks that have no real value) \cite{Bentov}.
In order to mitigate such shortcomings the PPCoin cryptocurrency in 2012 first utilized an
alternative consensus algorithm, Proof-of-Stake (PoS). \cite{Ppcoin}. In the PoS consensus networks
the probability of creating a new block depends on the volume of tokens deposited by an
participant. PoS also turns out to have several drawbacks and in its current state according
to a number of experts cannot serve an adequate replacement to PoW. \cite{Demeester}. The next
iteration of PoS was introduced as the Delegated Proof-of-Stake (DPoS) \cite{dantheman}. Nevertheless,
in DPoS there still remains a problem of motivation for participant to use their assets actively.
The Proof-of-Importance consensus algorithm (PoI), first introduced in the NEM
cryptocurrency \cite{nem}, rewards network participants’ activity. The major difference from PoS is that
the block generation probability and reward distribution depends not only on the volume of
deposit but also on the participant’s activity rate and reputation. Thus, the algorithm
incentivizes users to be more active by making more transactions and rewarding contribution
to the network growth.

\section{Gravity Protocol Consensus Algorithm Operation Principle}
The Gravity consensus algorithm (Delegated Proof-of-Importance, DPoI) is based on the
Graphene core consensus algorithm. Our algorithm, in addition to the node’s stake volume,
also considers the node’s transactional activity and connection topology with the other nodes
of the network. In the Gravity protocol all the participants vote for the delegates who validate block addition. To prevent activity imitation between several affiliated accounts the
transaction graph is partitioned into clusters utilizing the SCAN algorithm. In general terms
the principal of the Gravity consensus algorithm can be described as follows:


\subsection{Calculating the Importance Rating:}
The Importance Rating is calculated as follows:
$$
r_i = (v_i + \omega \pi_i) \chi_i
$$
In here $v_i$ is the stake volume index, $\pi$ i is the activity rating calculated with the
NCDawareRank algorithm, $\omega$ — the weight coefficient, $\chi_i$ – the account vertex graph
position modifier (1 when the vertex belongs to a cluster and 0.9 when the vertex is a hub or
an independent vertex).

\subsection{The NCDawareRank algorithm}
The Importance Rating within the NCDawareRank is calculated using the following recurrent
correlation:
$$
\boldsymbol{\pi}^{(i+1)} = ( \eta \boldsymbol{O} + \mu \boldsymbol{M} + ( 1 - \eta - \mu ) E ) \boldsymbol{\pi}^{(i)}
$$

$\pi^{(i)}$ is the vector every element of which is the account’s importance rating. The vector is
normalized, the sum of the elements is 1. O is the outlink matrix, M is the interlevel proximity
matrix. See the definitions of the matrices below. $\eta$ and $\mu$ are weight coefficients that
determine contributions of the O and M matrices. Their sum must be less than 1. E is the
teleport matrix added to ensure the series is convergent. It is defined as follows:
$$
\boldsymbol{E}=\frac{1}{N}\boldsymbol{e}
$$
where N is the number of accounts and e is the matrix in which all the elements are equal to
1. The calculation continues until for some i the following condition is fulfilled:
$$
norm(\boldsymbol{\pi}^{(i+1)}-\boldsymbol{\pi}^{(i)})<\varepsilon
$$
In here norm() is the vector norm defined as the sum of its elements,
$\varepsilon$ is the predetermined calculation accuracy. As an initial approximation, $\pi_0$, a vector with
all the elements equal to $\frac{1}{N}$ can be used.


\subsection{Outlink matrix calculation}
The outlink matrix $O$ is calculated as follows:
First the weight matrix is calculated:
$$
w_{ij}=\sum_{k|i \to j}a_k \exp{(lnK [\frac{h_k}{D}])}
$$
Where $a_k$ is the sum of transaction k, $h_k$ is the transaction depth (the block ordinal number
from the current point), $K$ and $D$ are transaction contribution decrease parameters, that
define how much the contribution of each transaction decreases over time. The point of
these parameters is that over every $D$ number of blocks, created after the given transaction,
the transaction contribution decreases by $w'=Kw$.

The sum is taken over all the transactions of a deposit from account i to account j.

$$
\hat{o}_{ij} = \begin{cases}
 w_{ji}-w_{ij}
 & \text{for $w_{ji}-w_{ij} > 0$,}\\
 0 & \text{otherwise.}
\end{cases}
$$
Then the obtained matrix is normalized so that the sum of elements in every column is equal
to 1.
$$
o_{ij} = \begin{cases}
 \frac{\hat{o}_{ij}} {\sum\limits_{j} \hat{o}_{ij}}
 & \text{for $\sum\limits_{j} \hat{o}_{ij}> 0$,}\\
 0 & \text{otherwise.}
\end{cases} 
$$

\subsection{Interlevel proximity matrix calculation}
W is an array of all the accounts taken into the Importance Index calculation; W is a set
divided into disjoint subsets $A_i$ called NCD-blocks (Nearly Completely Departed). See the
SCAN algorithm description for details. For the given “account u” “$G_u$” is the set of all the
accounts that have received from “account u” a larger sum, than they have sent to “account
u”. Then the set of proximal accounts u is defined as follows:

$$
\chi_u = \bigcup_{v \in \{u\} \cup G_u} A_{(v)}
$$
The interlevel proximity matrix is defined as follows:
$$
M_{vu}=\begin{cases}
 \frac{1}{N_u |A_{(v)}|}
 & \text{for $v \in \chi_u$ ,}\\
 0 & \text{otherwise.}
\end{cases}
$$

Here $N_u$ is the number of NCD-blocks in $\chi_u$.

\subsection{SCAN algorithm based graph partitioning into clusters}
An undirected graph $W = \{V, E\}$ has every vertex representing an account, and every edge
representing a non-zero element of the outlink matrix. The structure of the vertex v is the set of all the adjacent vertices:

$$
\Gamma(v)=\{w \in V|(v,w) \in E\} \cup \{v\}
$$
The structural similarity of two vertices can be defined as follows:
$$
\sigma(v,w)=\frac{ |\Gamma(v) \cap \Gamma(w)|}{\sqrt{|\Gamma(v)||\Gamma(w)|}}
$$

The vertex $\varepsilon$-neighborhood is a set of vertices for which

$$
N_{\varepsilon}(v) = \{ w \in \Gamma(v) | \sigma(v,w) \le \varepsilon \}
$$

The Core is a vertex for which the number of elements in the $\varepsilon$-neighborhood is more than $\mu$.


$$
CORE_{\varepsilon,\mu}(v) \Leftrightarrow |N \in (v)| \ge \mu
$$

Vertex w is directly structurally reachable from vertex v if

$$
DirREACH(v,w) \Leftrightarrow CORE_{\varepsilon,\mu}(v) \vee w \in N_{\varepsilon}(v)
$$

Vertex w is structurally reachable from vertex v if

$$
REACH(v,w) \Leftrightarrow \exists v_1,...v_n \in V \forall i \in \{1,...n-1\}DirREACH(v_i,v_{i+1})
$$
Vertex v is structurally connected with vertex w if

$$
CONNECT(v,w) \Leftrightarrow \exists u \in V REACH(u,v) \vee REACH(u,w)
$$
A cluster is a subset of vertices structurally connected with each other. It can be shown that
every vertex can only belong to one cluster. Also a vertex can belong to no cluster; in this
case it can either be a hub if in its environment there are vertices belonging to two different clusters, or an independent vertex otherwise.


\addcontentsline{toc}{section}{Bibliography}
\begin{thebibliography}{99}
 \bibitem{Metcalfe}Nakamoto, S. (2008). Metcalfe, B. (2013). Metcalfe's law after 40 years of ethernet. Computer, 46(12), 26-31.
 \url{http://ieeexplore.ieee.org/abstract/document/6636305/}
 \bibitem{Lamport}Lamport, L., Shostak, R., \& Pease, M. (1982). The Byzantine generals problem. ACM Transactions on Programming Languages and Systems (TOPLAS), 4(3), 382-401.
 \url{https://www.microsoft.com/en-us/research/uploads/prod/2016/12/The-Byzantine-Generals-Problem.pdf}
 \bibitem{Castro} Castro, M., \& Liskov, B. (2002). Practical Byzantine fault tolerance and proactive recovery. ACM Transactions on Computer Systems (TOCS), 20(4), 398-461.
 \url{https://dl.acm.org/citation.cfm?doid=571637.571640}
 \bibitem{satoshi}Nakamoto, S. (2008). Bitcoin: A peer-to-peer electronic cash system.
 \url{https://bitcoin.org/bitcoin.pdf}
 \bibitem{Croman} Croman, K. et al. (2016). On scaling decentralized blockchains. In International Conference on Financial Cryptography and Data Security (pp. 106-125). Springer, Berlin, Heidelberg.
 \url{http://www.comp.nus.edu.sg/~prateeks/papers/Bitcoin-scaling.pdf}
 \bibitem{Eyal} Eyal, I., \& Sirer, E. G. (2014). Majority is not enough: Bitcoin mining is vulnerable. In International conference on financial cryptography and data security (pp. 436-454). Springer, Berlin, Heidelberg.
 \url{https://arxiv.org/pdf/1311.0243.pdf}
 \bibitem{Buterin} Buterin, V. (2014). Mining Pool Centralization at Crisis Levels. bitcoinmagazine.com
 \url{https://bitcoinmagazine.com/articles/mining-pool-centralization-crisis-levels-1389302892/}
 \bibitem{Bentov} Bentov, I., Gabizon, A., \& Mizrahi, A. (2016). Cryptocurrencies without proof of work. In International Conference on Financial Cryptography and Data Security (pp. 142-157). Springer, Berlin, Heidelberg.
 \url{https://link.springer.com/chapter/10.1007/978-3-662-53357-4_10/}
 \bibitem{Ppcoin} King, S., \& Nadal, S. (2012). Ppcoin: Peer-to-peer crypto-currency with proof-of-stake. 
 \url{https://peercoin.net/assets/paper/peercoin-paper.pdf}
 \bibitem{Demeester} Demeester, T. (2017). Critique of Buterin’s “A Proof of Stake Design Philosophy”. medium.com 
 \url{https://medium.com/@tuurdemeester/critique-of-buterins-a-proof-of-stake-design-philosophy-49fc9ebb36c6}
 \bibitem{dantheman} Dantheman. (2017). DPOS Consensus Algorithm - The Missing White Paper. steemit.com 
 \url{https://steemit.com/dpos/@dantheman/dpos-consensus-algorithm-this-missing-white-paper}
 \bibitem{nem} NEM Technical Reference. Version 1.2.1. February 23, 2018
 \url{https://nem.io/wp-content/themes/nem/files/NEM_techRef.pdf}
 
\end{thebibliography}

\tableofcontents

\end{document}
