\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage[T2A]{fontenc}
\usepackage{amsmath}
\usepackage{hyperref}
\hypersetup{colorlinks=true}
\usepackage{colortbl}
\usepackage{graphicx}
\usepackage{float}

\pagecolor[rgb]{1,.98,.9}

\title{Gravity: протокол распределенного реестра управления данными}
\author{}

\begin{document}

\maketitle

\begin{abstract}
Концепция распределенного реестра транзакций защищенного криптографией продемонстрировала свою эффективность. Четвертая промышленная революция задает новый уровень требований к децентрализованным протоколам. Проект Gravity смотрит на задачи распределенного реестра через призму потребностей управления увеличивающемся массивом данных, создаваемых в результате экономической деятельности в цифровом обществе.  Архитектура протокола стремиться соответствовать этой задаче, используя алгоритм консенсуса Делегированное доказательство значимости (Delegated Proof of Importance, DPoI). DPoI - высокопроизводительный, энергоэффективный и стимулирующий развитие сети алгоритм, вознаграждающий участников сети за операции, являющуюся положительной для экономики системы. Делегированное доказательство значимости развивает существующие блокчейн решения, объединяя концепции  Делегированного доказательства доли (Delegated Proof of Stake, DPoS) и Теории сетей. Протокол системы спроектирован с учетом требований бизнеса и рядовых пользователей, таких, как приватность, аудируемость, мягкая волатильность, достигаемая за счет динамической эмиссии пропорциональной росту активности сети, опираясь на Закон Меткалфа.. \cite{Metcalfe}.
\end{abstract}

\section{Introduction / Введение}

Последние годы были отмечены необычайным ростом интереса к технологии блокчейн, при этом основным ее применением пока было создание распределенных платежных сетей. Такие сети являются децентрализованными и позволяют осуществлять быстрые и недорогие транзакции без посредников. Хотя экономические достоинства и недостатки платежных сетей, основанных на блокчейне, заслуживают отдельного рассмотрения в рамках данной бумаги мы планируем подробнее остановиться на технических особенности работы алгоритмов консенсуса в блокчейне.

Алгоритм консенсуса в блокчейне – это механизм, с помощью которого, в условиях отсутствия централизованного ведения журнала транзакций (реестра) одним субъектом, узлы сети могут достичь консенсуса о содержимом реестра. Именно алгоритм консенсуса является фундаментом любой блокчейн сети, в значительной степени определяющим ее технические особенности.

\subsection{Previous Work / Обзор литературы}
Задача распределенного консенсуса для сетей, в которых узлы могут быть злоумышленниками (т.н. задача византийских генералов), впервые была сформулирована задолго до появления блокчейна - в 1982 г. \cite{Lamport} С тех пор был разработан целый ряд различных вариантов ее решения \cite{Castro}, однако применительно к блокчейнам первым вариантом решения проблемы стал изложенный в статье Сатоши Накамото \cite{satoshi} алгоритм Proof-of-Work (PoW, доказательство работы). Несмотря на свои преимущества PoW характеризуется рядом недостатков: проблемы с масштабируемостью и производительностью \cite{Croman}, безопасностью \cite{Eyal}, постепенная централизация сети в руках крупнейших майнинг-пулов \cite{Buterin}, и самое важное - необходимость использования значительного объема реальных ресурсов (электроэнергии и вычислительной техники) для генерации каждого \cite{Bentov}. На сегодня вычислительные ресурсы, расходуемые на хеширование блоков в биткоине, огромны и намного превышают мощности крупнейших суперкомпьютеров, а расход энергии на майнинг сопоставим с потреблением электроэнергии целых стран и продолжает расти \cite{energy}.
Для устранения данных недостатков был придуман альтернативный алгоритм консенсуса - Proof-of-Stake (PoS, доказательство доли), впервые реализованный в 2012 году в криптовалюте PPCoin (сейчас известна под названием PeerCoin) \cite{Ppcoin}. В сетях с консенсусом PoS вероятность сформировать следующий блок зависит от объема токенов на депозите участника сети. Данный алгоритм также обладает рядом недостатков и, по мнению ряда экспертов, в текущем виде не является адекватной заменой PoW \cite{Demeester} \cite{Poelstra}. Одним из важнейших недостатков PoS является то, что он дает дополнительную мотивацию к накоплению средств в одних руках, что способствует централизации сети.
Развитием PoS стал алгоритм консенсуса Delegated Proof-of-Stake (DPoS, делегированное доказательство доли) \cite{dantheman}. Разделение участников сети на делегирующих и валидирующих (делегатов) обеспечивает лучшую масштабируемость и производительность. Однако в DPoS сохраняется проблема мотивации участников сети к консолидации токенов, вместо их активного использования, что отрицательно сказывается на росте и управляемости сети.
Для стимулирвоания активности участников сети был спроектирован алгоритм консенсуса Proof-of-importance (PoI, доказательство значимости), используемый в блокчейне NEM \cite{nem}. Ключевое отличие от PoS протоколов состоит в том, что при выборе валидатора блока учитывается не только баланс токенов акаунта, но и транзакционная активность участника. Таким образом, алгоритм мотивирует пользователей быть активными, совершая транзакции и поощряя участие в развитии сети. Несмотря на свои достоинства PoI не лишен недостатков связанных с производительностью. 

\subsection{Driving factor / Цель проекта}
Цель Gravity – создание протокола управления распределенным реестром с эффективным перераспределением влияния в системе, поощряющего пользователей принимать активное участие в развитии сети и препятствующего централизации. Для решения существующих в современных блокчейн решениях проблем с масштабируемостью, производительностью и безопасностью в протоколе Gravity реализован алгоритм достижения консенсуса DPoI (Delegated Proof of Importance). Алгоритм сочетает в себе достоинства DPoS и PoI, обладая преимуществами оных, реализует возможность делегирования права валидации блоков ограниченному количеству аккаунтов для достижения высокой производительности и масштабируемости сети, учитывая транзакционную активность участников протокола, способствуя ее развитию. 

\section{Принцип работы Gravity Protocol Consensus Algorithm}
Алгоритм консенсуса Gravity базируется на алгоритме Делегированное доказательство значимости (Delegated Proof of Importance, DPoI), основанном на изменённом ядре Graphene, учитывая дополнительно к доли владения узла его транзакционную активность. 
В протоколе Gravity всем аккаунта сети доступна возможность делегировать право валидировать блоки ограниченному кругу аккаунтов.
Для борьбы с имитацией активности между несколькими аффилированными аккаунтами используется разбиение транзакционного графа на кластеры с помощью алгоритма SCAN. В общих чертах принцип работы алгоритма консенсуса протокола Gravity можно представить следующим образом:

\subsection{Вычисление индекса значимости}
Индекс значимости эккаунта (называемый также gravity индексом) вычисляется следующим образом:
$$
r_i = (1 - \omega) v_i + \omega \pi_i
$$
Здесь $v_i$ – индекс доли владения, $\pi_i$ – индекс активности, полученный с помощью алгоритма NCDAwareRank, $\omega$ — весовой коэффициент.

Индекс доли владения определяется количеством токенов, принадлежащих эккаунту, и представляет собой отношение баланса эккаунта к общему количеству токенов в системе. Таким образом, у любого эккаунта с ненулевым балансом будет ненулевой индекс знасимости. Индекс активности зависит от истории транзакций, связанных с данным эккаунтом. Индекс активности вычисляется не для всех эккаунтов, а для тех, баланс которых превышает некоторый порог $A_0$. Это значение не является фиксированным, и определяется участниками комитета. Также при вычислении инекса активности учитываются не все транзакции, а только те, в которых сумма передаваемых токенов превышает порог $T_0$, который также определяется комитетом.

\subsection{Алгоритм NCDAwareRank}
Индекс активности в соответствии с алгоритмом NCDAwareRank вычисляется с помощью следующего рекуррентного соотношения:
$$
\boldsymbol{\pi}^{(i+1)} = ( \eta \boldsymbol{O} + \mu \boldsymbol{M} + ( 1 - \eta - \mu ) \boldsymbol{E} ) \boldsymbol{\pi}^{(i)}
$$
$\pi^{(i)}$ -- вектор, каждый элемент которого -- рейтинг значимости эккаунта. Вектор нормированный, сумма его элементов равна 1.
$\boldsymbol{O}$ -- outlink-матрица, $\boldsymbol{M}$ – матрица межуровневой близости. Об определении этих матриц см. ниже.
$\eta$ и $\mu$ – весовые коэффициенты, определяющие вклад матриц $\boldsymbol{O}$ и $\boldsymbol{M}$. Их сумма должна быть меньше единицы.
$\boldsymbol{E}$ -- матрица телепортации, добавленная для обеспечения сходимости ряда. Она определяется так:
$$
\boldsymbol{E}=\frac{1}{N}\boldsymbol{e}
$$
где N -- количество эккаунтов, и $\boldsymbol{e}$ -- матрица, все элементы которой равны 1.
Вычисления продолжаются, пока при некотором i не будет выполнено условие:
$$
norm(\boldsymbol{\pi}^{(i+1)}-\boldsymbol{\pi}^{(i)})<\varepsilon
$$
Здесь norm() - это норма вектора, определенная как сумма его элементов, $\varepsilon$ — заранее заданная точность вычислений. 
В качестве начального приближения, $\pi_0$, может быть использован вектор, все элементы которого равны $\frac{1}{N}$.

\subsection{Вычисление outlink-матрицы}
Outlink-матрица $O$ вычисляется следующим образом. Сначала вычисляется матрица весов:
$$
w_{ij}=\sum_{k|i \to j}a_k \exp{(lnK [\frac{h_k}{D}])}
$$
Здесь $a_k$ – сумма k-й транзакции, $h_k$ – глубина  k-й транзакции (порядковый номер блока, отсчитанный от текущего момента), $K$ и  $D$ — параметры, определяющие, насколько уменьшается вклад каждой транзакции со временем. Смысл этих параметров в том, что каждые $D$ блоков, созданных после определенной транзакции, ее вклад уменьшается как $w'=Kw$.

Суммирование ведется по всем транзакциям, перемещающим некоторую сумму с эккаунта i на эккаунт j.
$$
\hat{o}_{ij} = \begin{cases}
 w_{ji}-w_{ij}
 & \text{если $w_{ji}-w_{ij} > 0$,}\\
 0 & \text{в ином случае.}
\end{cases}
$$
Далее, полученная матрица нормируется таким образом, что сумма элементов в каждом столбце была равна единице. 

$$
o_{ij} = \begin{cases}
 \frac{\hat{o}_{ij}} {\sum\limits_{j} \hat{o}_{ij}}
 & \text{если $\sum\limits_{j} \hat{o}_{ij}> 0$,}\\
 0 & \text{в ином случае.}
\end{cases} 
$$

\subsection{Вычисление матрицы межуровневой близости}

Множество всех аккаунтов W, участвующих в расчете индекса значимости, разбивается на непересекающиеся подмножества $A_i$, называемые NCD-блоками (NCD – nearly completely departed). О принципе разбиения см. описание алгоритма SCAN. 
Для данного эккаунта u рассмотрим множество всех эккаунтов $G_u$, которые получили от эккаунта u большую сумму, чем оправили ему. Множество ближних эккаунтов u тогда определяется следующим образом:

$$
\chi_u = \bigcup_{v \in \{u\} \cup G_u} A_{(v)}
$$
Матрица межуровневой близости определяется тогда так:
$$
M_{vu}=\begin{cases}
 \frac{1}{N_u |A_{(v)}|}
 & \text{если $v \in \chi_u$ ,}\\
 0 & \text{в ином случае.}
\end{cases}
$$
Здесь $N_u$ означает число NCD-блоков в $\chi_u$.

\subsection{Разбиение графа на кластеры с помощью алгоритма SCAN}
Построим ненаправленный граф $W = \{V, E\}$, в котором каждая вершина соответствует эккаунту, и каждое ребро – ненулевому элементу outlink-матрицы.
Структурой данной вершины v назовем множество всех соседних вершин:
$$
\Gamma(v)=\{w \in V|(v,w) \in E\} \cup \{v\}
$$

Структурным сходством двух вершин назовем следующую величину:
$$
\sigma(v,w)=\frac{ |\Gamma(v) \cap \Gamma(w)|}{\sqrt{|\Gamma(v)||\Gamma(w)|}}
$$
$\varepsilon$-окружением вершины назовем множество вершин такое, что
$$
N_{\varepsilon}(v) = \{ w \in \Gamma(v) | \sigma(v,w) \ge \varepsilon \}
$$
Ядром назовем вершину, у которой число элементов в $\varepsilon$-окружении больше некоторого порога $\mu$.
$$
CORE_{\varepsilon,\mu}(v) \Leftrightarrow |N_{\varepsilon} (v)| \ge \mu
$$
Вершина w находится в прямой структурной доступности от вершины v, если
$$
DirREACH(v,w) \Leftrightarrow CORE_{\varepsilon,\mu}(v) \vee w \in N_{\varepsilon}(v)
$$
Вершина w находится в структурной доступности от вершины v, если
$$
REACH(v,w) \Leftrightarrow \exists v_1,...v_n \in V \forall i \in \{1,...n-1\}DirREACH(v_i,v_{i+1})
$$
Вершина v структурно соединена с вершиной w, если
$$
CONNECT(v,w) \Leftrightarrow \exists u \in V REACH(u,v) \vee REACH(u,w)
$$
Подмножество вершин, каждая из которых структурно соединена совсем остальными, называется кластером. Можно показать, что каждая вершина может принадлежать только одному кластеру. Также вершина может не принадлежать ни к одному из кластеров, в этом случае она называется значимым узлом, если среди соседей этой вершины есть такие, которые принадлежат к двум разным кластерам, и отдельно стоящей вершиной в противном случае.

\subsection{Использование индекса значимости в системе}
Индекс значимости используется для двух целей. 

Во-первых, при очередной эмиссии индекс значимости определяет долю новых токенов, которыю получит каждый эккаунт.

Во-вторых, индекс значимости определяет вес данного эккаунта при голосовании. Голосование позволяет делегировать определенные полномочия в системе ограниченному количеству эккаунтов.

Путем голосования выбираются узлы, которые осуществляют формирование блоков. 

Также путем голосования выбираются члены комитета. Комитет может голосованием менять параметры блокчейна, такие, как размер комиссии за трансфер, вознаграждение witness-нодам и т.п.


\section{Масштабируемость}

\section{Защита / Security}

\section{Токен протокола}
Объём обрабатываемых операций блокчейн протоколом напрямую зависит от доступной вычислительной мощности, предоставленной участниками сети. Для эффективного распределения ресурсов системы и предотвращения spam атак, при совершении операций в сети Gravity с пользователей удерживается комиссия системы в криптографическом токене протокола.. 
Протокол позволяет совершать транзакции трансфера токена между аккаунтами участников сети и вызова умных контрактов системы, таких как мульти-подпись, регистрация аккаунтов, создание пользовательских токенов и т.д.. 

\section{Эмиссия и распределение премайнед монет}

Стартовая эмиссия составляет 1000000000 токенов протокола, распространяется по изначальным аккаунтам сети для запуска функционирования протокола.   
В проекте Gravity используется динамическая эмиссия. Эмиссия производится регулярно, в моменты времени $t_0, t_1, ... t_i$, где $t_{i+1} = t_i + T$. Объем эмиссии зависит от роста активности сети за предыдущий период T.

\subsection{Вычисление активности сети за период}

Вычислим сперва матрицу весов по следующей формуле:

$$
w_{ij}(t_n)=\sum_{k|i \to j, t_k \in [t_{n-1}, t_n]}a_k
$$

Здесь $a_k$ – сумма k-й транзакции, $t_k$ – время создания k-й транзакции. Суммирование ведется по всем транзакциям, перемещающим некоторую сумму с эккаунта i на эккаунт j, созданным за период от $t_{n-1}$ до $t_n$.

Каждый элемент матрицы $w_{ij}$ представляет собой вес связи между эккаунтом $i$ и $j$ за данный период.

Вычислим теперь матрицу связей $l$:

$$
l_{ij}(t_n) = \begin{cases}
 1
 & \text{если $w_{ji}(t_n)-w_{ij}(t_n) > 0$,}\\
 0 & \text{в ином случае.}
\end{cases}
$$

Активность за период мы будем вычислять так:

$$
A(t_n) = \sum_{i,j} l_{ij}(t_n)
$$

Таким образом, активность вычисляется как количество связей между активными эккаунтами за данный период.

\subsection{Вычисление объема эмиссии}

Объем эмиссии зависит от роста активности сети.

Определим величину $E_T$, которую назовем целевой величиной эмиссии. Она задает верхнюю границу совокупной величины эмиссии, достижимой при данном значении активности A.

$$
\Delta A(t_n) = A(t_n) - A_{max}(t_{n-1})
$$

$$
E_T(t_n) = \begin{cases}
 E_T(t_{n-1}) + K_E \Delta A(t_n),
 & \text{если $\Delta A(t_n) > 0$,}\\
 0 & \text{в ином случае.}
\end{cases}
$$

Здесь $K_E$ - коэффициент, определяющий максимальную величину эмиссии при увеличении активности на единицу, $A_{max}(t_{n-1})$ - максимальное предыдущее значение активности с момента запуска системы:

$$
    A_{max}(t_{n-1}) = max \Big ( A(t_i), t_i \in [t_0, t_{n-1}] \Big )
$$

Величина эмиссии, выпускаемая в момент времени t, вычисляется по формуле:

$$
    E(t_n) = \lambda S(t_{n-1}) f \Big( \kappa \frac {E_T(t_n) - S(t_{n-1})}{\lambda S(t_{n-1})} \Big)
$$

Здесь $\lambda$ -- предельный рост количества токенов в системе S за один выпуск эмиссии. Он определяется из параметра L, который задает предельный рост S в год (выраженный в процентах):

$$
    \lambda = (1 + \frac{L}{100})^{1/N}-1
$$

Здесь N - количество выпусков эмиссии в год.

$f(x)$ - сигмоидальная функция (Рис. \ref{fig:sigmoida}). В имеющейся реализации алогитма в качестве этой функции используется гиперболический тангенс.

$\kappa$ -- коэффициент от 0 до 1, определяющий скорость, с которой полная эмиссия приближается к целевой эмиссии $E_T$, в случае, если активность остается но одном уровне на протяжении длительного срока.

\begin{figure}[h]
      \includegraphics[width=1\linewidth]{pictures/sigmoida.eps}
      \caption{Сигмоидальная функция}
      \label{fig:sigmoida}
\end{figure}

\subsection{Анализ формулы динамической эмиссии}






\section{Заключение}

\addcontentsline{toc}{section}{Список литературы}
\begin{thebibliography}{99}
 \bibitem{Metcalfe} Metcalfe, B. (2013). Metcalfe's law after 40 years of ethernet. Computer, 46(12), 26-31. URL: http://ieeexplore.ieee.org/abstract/document/6636305/
 \bibitem{Lamport} Lamport, L., Shostak, R., Pease, M. (1982). The Byzantine generals problem. ACM Transactions on Programming Languages and Systems (TOPLAS), 4(3), 382-401. URL: https://www.microsoft.com/en-us/research/uploads/prod/2016/12/The-Byzantine-Generals-Problem.pdf
 \bibitem{Castro} Castro, M., Liskov, B. (2002). Practical Byzantine fault tolerance and proactive recovery. ACM Transactions on Computer Systems (TOCS), 20(4), 398-461. URL: https://dl.acm.org/citation.cfm?doid=571637.571640
 \bibitem{satoshi} Nakamoto, S. (2008). Bitcoin: A peer-to-peer electronic cash system. URL: https://bitcoin.org/bitcoin.pdf
 \bibitem{Croman} Croman, K. et al. (2016). On scaling decentralized blockchains. In International Conference on Financial Cryptography and Data Security (pp. 106-125). Springer, Berlin, Heidelberg. URL: http://www.comp.nus.edu.sg/~prateeks/papers/Bitcoin-scaling.pdf
 \bibitem{Eyal} Eyal, I., Sirer, E. G. (2014). Majority is not enough: Bitcoin mining is vulnerable. In International conference on financial cryptography and data security (pp. 436-454). Springer, Berlin, Heidelberg. URL: https://arxiv.org/pdf/1311.0243.pdf
 \bibitem{energy} Bitcoin Energy Consumption Index. digiconomist.net. URL: https://digiconomist.net/bitcoin-energy-consumption
 \bibitem{Buterin} Buterin, V. (2014). Mining Pool Centralization at Crisis Levels. URL: https://bitcoinmagazine.com/articles/mining-pool-centralization-crisis-levels-1389302892/
 \bibitem{Bentov} Bentov, I., Gabizon, A., Mizrahi, A. (2016). Cryptocurrencies without proof of work. In International Conference on Financial Cryptography and Data Security (pp. 142-157). Springer, Berlin, Heidelberg. URL: https://link.springer.com/chapter/10.1007/978-3-662-53357-4\_10/
 \bibitem{Ppcoin} King, S., Nadal, S. (2012). Ppcoin: Peer-to-peer crypto-currency with proof-of-stake. URL: https://peercoin.net/assets/paper/peercoin-paper.pdf
 \bibitem{Demeester} Demeester, T. (2017). Critique of Buterin’s A Proof of Stake Design Philosophy. URL: https://medium.com/@tuurdemeester/critique-of-buterins-a-proof-of-stake-design-philosophy-49fc9ebb36c6
 \bibitem{Poelstra} Poelstra, A. (2014). Distributed consensus from proof of stake is impossible. URL: https://download.wpsoftware.net/bitcoin/old-pos.pdf
 \bibitem{dantheman} Dantheman. (2017). DPOS Consensus Algorithm - The Missing White Paper. URL: https://steemit.com/dpos/@dantheman/dpos-consensus-algorithm-this-missing-white-paper
 \bibitem{nem} NEM Technical Reference. Version 1.2.1. February 23, 2018 URL: https://nem.io/wp-content/themes/nem/files/NEM\_techRef.pdf
\end{thebibliography}


\tableofcontents

\end{document}
